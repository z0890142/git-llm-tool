# Example configuration for git-llm-tool with LangChain integration
# Save this as .git-llm-tool.yaml in your project root or ~/.git-llm-tool/config.yaml

llm:
  # Model selection (will use appropriate LangChain provider)
  default_model: "gpt-4o"  # or "claude-3-5-sonnet-20241024", "gpt-4", etc.

  # Language for commit messages
  language: "en"  # or "zh", "ja", etc.

  # API Keys (set via environment variables or config commands)
  api_keys:
    openai: "your-openai-api-key"
    anthropic: "your-anthropic-api-key"

  # Processing strategy threshold (tokens)
  # Below this threshold: single request processing
  # Above this threshold: intelligent chunking with parallel processing
  chunking_threshold: 12000      # Token threshold to trigger chunking (default: 12000)

  # Hybrid Ollama processing (optional)
  # Use local Ollama for chunk processing (map phase), cloud LLM for final result (reduce phase)
  use_ollama_for_chunks: false   # Enable Ollama for chunk processing (default: false)
  ollama_model: "llama3:8b"      # Ollama model for chunks (default: "llama3:8b")
  ollama_base_url: "http://localhost:11434"  # Ollama API URL (default: "http://localhost:11434")

# Jira integration (optional)
jira:
  enabled: true
  ticket_pattern: "[A-Z]+-\\d+"  # Regex pattern to match Jira tickets in branch names

# Editor preferences (optional)
editor:
  preferred_editor: "code"  # or "vi", "nano", etc.